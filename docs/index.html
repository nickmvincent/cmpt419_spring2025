<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Course Website</title>
  <link rel="stylesheet" href="assets/style.css">
</head>
<body>
  <div class="sidebar">
    <nav><ul class="nav-list">
<li class="nav-section">
<div class="nav-section-header">Home</div>
<ul class="nav-items">
<li><a href="#home">Home</a></li>
</ul></li>
<li class="nav-section">
<div class="nav-section-header">readings</div>
<ul class="nav-items">
<li><a href="#readings-Course_Readings">Course Readings</a></li>
<li><a href="#readings-Optional_Classics">Optional Classics</a></li>
<li><a href="#readings-Optional_LateBreaking">Optional Latebreaking</a></li>
<li><a href="#readings-Readings_TLDR">Readings Tldr</a></li>
</ul></li>
<li class="nav-section">
<div class="nav-section-header">assignments</div>
<ul class="nav-items">
<li><a href="#assignments-assignment_1_tools">Assignment 1 Tools</a></li>
<li><a href="#assignments-assignment_2_influence">Assignment 2 Influence</a></li>
<li><a href="#assignments-project_proposal">Project Proposal</a></li>
<li><a href="#assignments-project_rubric">Project Rubric</a></li>
</ul></li>
<li class="nav-section">
<div class="nav-section-header">misc</div>
<ul class="nav-items">
<li><a href="#misc-Key_Dates">Key Dates</a></li>
<li><a href="#misc-Lecture_Erratum">Lecture Erratum</a></li>
<li><a href="#misc-Prerequisites_Doc">Prerequisites Doc</a></li>
</ul></li>
<li class="nav-section">
<div class="nav-section-header">slides_pdfs</div>
<ul class="nav-items">
<li><a href="#slides_pdfs-Week1-Part1">Week1-Part1</a></li>
<li><a href="#slides_pdfs-Week1-Part2">Week1-Part2</a></li>
<li><a href="#slides_pdfs-Week2">Week2</a></li>
<li><a href="#slides_pdfs-Week3">Week3</a></li>
<li><a href="#slides_pdfs-Week4">Week4</a></li>
<li><a href="#slides_pdfs-Week5">Week5</a></li>
<li><a href="#slides_pdfs-Week6">Week6</a></li>
</ul></li>
</ul></nav>
  </div>
  <div class="content">
    <section id="home" class="page-section active">
<h1>Home</h1>
<h1 id="syllabus-cmpt-419-d200-nicholas-vincent-spring-2025">Syllabus: CMPT 419 D200, Nicholas Vincent, Spring 2025</h1>
<h2 id="lectures-and-office-hours">Lectures and Office Hours</h2>
<p>Classes are on Tuesday/Thursday. See go.sfu.ca for exact location and time. </p>
<p>We will have office hours for an hour after class starting Week 2. Location TBA.</p>
<p>We will have additional office hours by appointment and/or popular demand.</p>
<h2 id="general-structure-of-our-lecture-time">General structure of our &ldquo;lecture&rdquo; time:</h2>
<ul>
<li>Each Tuesday (1 hr sessions), we’ll briefly discuss the previous week’s readings, I’ll introduce any readings and assignments for the week, and I&rsquo;ll start the &ldquo;lecture content&rdquo; for the week.</li>
<li>I’ll aim to hold at least 5-10 min every Monday to walk through assignments together and take questions. You’re welcome to use this time to start working and see if questions arise.</li>
<li>On Thursday (2 hr sessions), we’ll finish lecture content and have a discussion about the lecture/readings for the first hour, and then typically use the second hour for some kind of activity or &ldquo;lab time&rdquo;. We may use some of this time to work on assignments and projects and to take quizzes or practice quizzes.</li>
<li>I’ll always take questions at the beginning and end of each lecture session. You’re always welcome to email me, but I may take 2-3 business days to respond to emails. Asking questions in class will provide a quicker response and your classmates may benefit from your questions as well!</li>
</ul>
<p>This course is designed to have a particularly heavy reading and discussion component. Please be prepared to read quite a bit of material, and to talk about it.</p>
<h2 id="about-course-assignments">About course assignments:</h2>
<p>Each week has a set of assigned readings:</p>
<ul>
<li>There will be a set of mandatory readings.</li>
<li>There will also be some optional readings. You are encouraged to read the abstracts and/or Introduction sections of the optional readings to see if they align with what you hope to get out of the class. I’ll do my best to organize these by theme, and will add more based on the interests you express.</li>
<li>Each week, you’ll submit some relatively brief “reading responses” via Coursys. These will be very lightly graded (there really aren&rsquo;t wrong answers). However, you should be prepared to defend your reading responses live in class (i.e. I may cold call students, and you should be able to speak to your reading response in a way that suggest you did indeed read the required material, but you need not agree with the arguments presented or understand all the material).</li>
<li>For readings, I strongly recommend against AI assistant. I personally prefer that you submit bullet points rather than bullet points that prompt an LLM to output flowerly text.</li>
</ul>
<p>Reading schedule:</p>
<ul>
<li>Assigned readings for Week X are considered “finalized” on Tuesday of the preceding week (Week X-1), and should be completed by Tuesday of Week X. Each reading response is due immediately before class begins.<ul>
<li>For example: During class on Tuesday of Week 1, I’ll post and tell you all the required readings for Week 2, which you should finish over the next 7 days.</li>
<li>I’ll try to provide a solid &ldquo;look ahead&rdquo; of course material, but it may be subject to change based on your feedback, course progress, and even current events – so you should check the readings each Tuesday after class. For instance, in the past, I have extended time to complete readings that students found particularly dense.</li>
</ul>
</li>
</ul>
<h2 id="about-course-organization">About course organization</h2>
<p>The course will be organized roughly in terms of 4 “modules”:</p>
<ul>
<li>Module 1: Administration and Introduction to Different Frameworks for doing &ldquo;Human-Centered&rdquo; or &ldquo;Data-Centered&rdquo; Work (Weeks 1-4)</li>
<li>Module 2: Technical work in Data Valuation and Scaling. (Weeks 5-7, 3 in total)</li>
<li>Module 3: Online platforms and Content Ecosystems. (Weeks 8-10, 3 in total).</li>
<li>Module 4: Frontiers in Data Governance: Voting, Markets, and More (Week 11-13, 3 in total).</li>
</ul>
<p>We will have one assignment per module (coding / data analysis).</p>
<h2 id="grading">Grading</h2>
<ul>
<li>10% reading responses<ul>
<li>10 total reading responses, each worth 1%</li>
</ul>
</li>
<li>20% coding assignments</li>
<li>30% quizzes</li>
<li>40% final project</li>
</ul>
<h2 id="course-faqs">Course FAQs</h2>
<p>Q: Is attendance mandatory?</p>
<p>A: While I won’t give you direct marks for attendance, you are highly encouraged to attend class whenever you are able to. I do expect all students to participate in class discussion at some point (i.e. I do want everybody to speak up at least once). I will try to facilitate this &ldquo;softly&rdquo; via some cold-calling to discuss reading responses but this will not be strictly enforced (e.g., if circumstances arise, we can meet in office hours to discuss your progress in the course). If a very &ldquo;loose approach&rdquo; to soliciting participation isn&rsquo;t working at the mid-point to class, we&rsquo;ll discuss (as a class) alternatives.</p>
<p>I am very supportive of students staying home when sick, and understand a variety of personal situations may arise that prevent you from going to class. You do not need to email me to miss class, but are welcome to ask follow up questions (I may just point you to the class notes and encourage you to talk to your classmates). To earn a high mark in this class, I encourage you to plan to attend all lectures you are able to.</p>
<hr />
<p>Q: Will this class involve coding?</p>
<p>A: Yes, there will be some coding assignments in the class that are designed to give hands-on experience with certain course concepts. You are free to use a variety of programming languages and tools for these assignments, though will be encouraged to use some “standard” solutions based (primarily: Python for ML and data science related components, Javascript and web-programming for some design components). For coding assignment, LLM assistance will be allowed (with some caveats). I expect available LLM tooling to change quite a bit <em>during</em> our semester, so we&rsquo;ll play with tools together as part of the course.</p>
<hr />
<p>Q: How many assignments will we have?</p>
<p>A: You will complete 4 assignments (involving coding and data analysis) and 1 project.</p>
<hr />
<p>Q: Can I work in a group?</p>
<p>A: There will be opportunities to do group work, but you must write a contribution statement for everything. You must review all your team’s code and writing! Individual assignments that allow group work will have specific details for how this will work.</p>
<hr />
<p>Q: Are there quizzes, a midterm, and/or a final exam?</p>
<p>A: There will be in-class quizzes, but no &ldquo;midterm&rdquo; or &ldquo;final&rdquo;. There will be one quiz for each module (4 total). They will be announced in advance and some kind of make-up option will be available for sick students. Any “testable” material will be drawn only from in class lecture materials and mandatory readings. The goal of the quizzes is to provide additional incentives to engage with material each week.</p>
<hr />
<p>Q: What materials do I need?</p>
<p>Reading materials will be provided digitally by the instructor. There will be no single textbook &ndash; rather, we will read an assortment of research papers, book chapters, etc. You will be asked to spend some time installing software tools on your own. You will have some flexibility in which tools you choose – there will always be a free option available.</p>
<hr />
<p>Q: Can I use ChatGPT (etc.)?</p>
<p>A: You may use generative AI tools to assist with your coursework, but must provide complete logs for any outputs you use directly and any artifacts you submit should indicate the provenance of any generative AI outputs. </p>
<p>e.g.</p>
<ul>
<li>“This slide was produced by model XYZ”</li>
<li>“This summary paragraph or code snippet was produced entirely by ChatGPT”</li>
<li>“This code was generated with the help of ChatGPT, but heavily edited”</li>
</ul>
<p>Individual assignments may have specific requirements you should pay attention to</p>
</section>
<section id="readings-Course_Readings" class="page-section ">
<h1>Course Readings</h1>
<h2 id="week-2">Week 2</h2>
<p>The goal of the week 2 readings is to begin getting some exposure to what different researchers mean when they refer to human and data centered ML/AI. We want to start developing some intuiton for when human-centered practices or data-centred thinking might materially change how we design a system, come up with a research question, or deploy a model.</p>
<p>Reading 1: Chancellor 2023.</p>
<ul>
<li>Citation: Chancellor, S., 2023. Toward practices for human-centered machine learning. Communications of the ACM, 66(3), pp.78-85.</li>
<li>About: First, we&rsquo;ll read “Toward Practices for Human-Centered Machine Learning” by Stevie Chancellor, published in the Communications of the ACM. CACM is a venue in which experts in various fields of computing write broad pieces for the entire computing community.</li>
<li>How to access: Visit https://cacm.acm.org/magazines/2023/3/270209-toward-practices-for-human-centered-machine-learning/fulltext</li>
</ul>
<p>Reading 2: Mazmunder et al. 2022.</p>
<ul>
<li>Citation: Mazumder, M., Banbury, C., Yao, X., Karlaš, B., Gaviria Rojas, W., Diamos, S., Diamos, G., He, L., Parrish, A., Kirk, H.R. and Quaye, J., 2023. Dataperf: Benchmarks for data-centric ai development. Advances in Neural Information Processing Systems, 36, pp.5320-5347.</li>
<li>About: Second, we&rsquo;ll read the Introduction of the DataPerfs paper, published in NeurIPS 2023 Datasets and Benchmarks Track.</li>
<li>How to access: Visit https://arxiv.org/abs/2207.10062 </li>
<li>Notes: You only need to read the Introduction this week.</li>
</ul>
<h3 id="response-instructions">Response Instructions:</h3>
<p>1) Please write one to two paragraphs describing why you’d like to work on, or with, ML/AI systems? You can imagine these paragraphs as text you might include in a cover letter.<br />
2) Please list 1-3 “domains of interest” (e.g., social media, content recommendation, law, health care, mental health, the environment, economics). They can be at any level of granularity (e.g. “AI for health” is OK, as is “AI for oncology”). Similarly to part 1, the purpose of this is to help me identify trends in your interests so I can suggest optional readings that are of interest to you and your classmates!</p>
<p>If you submit any reasonable formatted submission for this reading response, you&rsquo;ll receive full credit. In future response instructions, you might see something along the lines of, &ldquo;you must quote on of the readings directly to support your point&rdquo;).</p>
<p>For this reading response, you&rsquo;ll submit via CourSys.</p>
<p>Optional reading</p>
<ul>
<li>If interested in data-centric approach to large language models, check out this blog: https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html </li>
</ul>
<h2 id="week-3">Week 3</h2>
<p>The goal of the week 3 reading is to gain further exposure to various frameworks put forward around focusing on humans (Schneiderman reading) and/or data (Sambasivan et al reading and Zha et al reading).</p>
<p>Note this week is a bit longer than than Week 2. We&rsquo;ll check in on how it&rsquo;s going, workflow wise, to complete these readings, and focus on challenges that may come up for those who haven&rsquo;t had many reading heavy computing classes previously.</p>
<p>Reading 1: Shneiderman 2020.</p>
<ul>
<li>Citation: Shneiderman, B., 2020. Human-centered artificial intelligence: Reliable, safe &amp; trustworthy. International Journal of Human–Computer Interaction, 36(6), pp.495-504.</li>
<li>About: This is a paper published in the International Journal of Human–Computer Interaction.</li>
<li>How to access: visit https://www.tandfonline.com/doi/full/10.1080/10447318.2020.1741118 on campus or https://arxiv.org/abs/2002.04087 off campus</li>
</ul>
<p>Reading 2: Sambasivan et al 2021.</p>
<ul>
<li>Citation: Sambasivan, N., Kapania, S., Highfill, H., Akrong, D., Paritosh, P. and Aroyo, L.M., 2021, May. “Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI. In proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-15).</li>
<li>About: This is a paper published in ACM CHI, the main venue for human-computer interaction research. </li>
<li>How to access: visit https://research.google/pubs/everyone-wants-to-do-the-model-work-not-the-data-work-data-cascades-in-high-stakes-ai/</li>
</ul>
<p>Reading 3: Zha et al 2023.</p>
<ul>
<li>Citation: Zha, D., Bhat, Z.P., Lai, K.H., Yang, F. and Hu, X., 2023. Data-centric ai: Perspectives and challenges. In Proceedings of the 2023 SIAM International Conference on Data Mining (SDM) (pp. 945-948). Society for Industrial and Applied Mathematics.</li>
<li>About: This is a short perspective paper in a data mining conference.</li>
<li>How to access: visit https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch106</li>
<li>Notes: you should read the short perspective paper. You may optionally also check out the longer survey paper and repo linked here: https://github.com/daochenzha/data-centric-AI</li>
</ul>
<p>Optional (mainly to give some more examples of academics using human- or data-centric framing):</p>
<ul>
<li>https://dl.acm.org/doi/abs/10.1145/3517337</li>
<li>https://arxiv.org/abs/2311.06703v2</li>
<li>https://dl.acm.org/doi/10.1145/3544549.3585752</li>
</ul>
<h3 id="response-instructions_1">Response Instructions</h3>
<p>Imagine you are a manager at a large tech company tasked with developing a new AI product. You can pick one of the following three options based on your interests, or suggest your own product:</p>
<ul>
<li>A large language model that will read physician notes and make suggestions about how to treat patients</li>
<li>A recommender system for a video-based content app</li>
<li>A facial recognition system that will be sold via API credits</li>
</ul>
<p>Q1: Thought experiment: Please write 1-2 paragraphs describing how adopting any of the suggestions from any of this week’s readings might change your product features (first define the product). Please directly reference (e.g. directly quote) one or more of the readings.</p>
<p>Q2: Please list three examples of “harms” that might occur from a failure to do “data work” as defined in the Sambasivan reading. You can use the same AI product you picked for Q1, or discuss one or more different AI products. You don’t need to quote the reading directly for this part.</p>
<p>Q3: Quick retrieval question: According to Zha et al., what category would each of the following techniques fall into: feature selection, creating images with randomly occluded patches, using Mechanical Turk to label documents.</p>
<p>Q4: Please let me know roughly how the long the readings and responses took so we can calibrate!</p>
<h2 id="week-4">Week 4</h2>
<p>For this week, there will be just two readings. The goal this week is still to gain exposure to all the different frameworks for thinking that motivate &ldquo;human-centered AI&rdquo; and &ldquo;data-centered AI&rdquo;. Last week, we saw several more frameworks, and in particular learned more about specific &ldquo;data-centric&rdquo; task formulations.</p>
<p>In our first reading, Chancellor highlighted that human-centered ML is often tied deeply to specific goals around fairness, justice, and values. This week, we&rsquo;ll dive into this with a reading from a textbook.</p>
<p>This week we&rsquo;ll just read two pieces: one is a longer introduction to a fairness in ML textbook, and the other is the Introduction to another research paper.</p>
<p>Please read the Introduction of FairML: https://fairmlbook.org/introduction.html</p>
<ul>
<li>While our course material will differ in some ways from a Special Topics course that&rsquo;s entirely focused on fair ML, there&rsquo;s quite a bit of conceptual overlap between being human-centered and trying to achieve some notion of fairness.</li>
<li>For our purposes, the concept of the &ldquo;machine learning loop&rdquo;, and especially measurements and going &ldquo;from data to models&rdquo; will be highly salient to almost all the topics we discuss, so try to read this one closely! We&rsquo;ll discuss this quite a bit together in class as well.</li>
</ul>
<p>Please read the Introduction of “Value-Sensitive Algorithm Design: Method, Case Study, and Lessons” by Zhu et al, published in CSCW: https://dl.acm.org/doi/10.1145/3274463 </p>
<p>The goal of this reading is to see another example of how a research project might concretely seek to incorporate values into design. You don&rsquo;t need to read the full paper, though if you&rsquo;re particularly interested in working on algorithm design you might want to!</p>
<h3 id="response-instructions_2">Response Instructions:</h3>
<p>Q1: Please summarize in your own words the idea of the &ldquo;machine learning loop&rdquo;. Do your best to capture the key concepts from the FairML intro.</p>
<p>Q2: How does the discussion of feedback loops in FairML Introduction compare to the discussion of feedback in Schneiderman&rsquo;s HCAI? You can just write 2-3 sentences describing major differences or similarities you see. There&rsquo;s not a correct answer here.</p>
<p>Q3: Quick retrieval: What online platform do Zhu et al. use to study value-sensitive design in a real-world setting?</p>
<p>Q4: Please let me know roughly how the long the readings and responses took so I can continue to calibrate!</p>
<h2 id="week-5">Week 5</h2>
<p>This week, we are going to start reading a long piece that surveys training data influence:</p>
<ul>
<li>Citation: Hammoudeh, Z. and Lowd, D., 2024. Training data influence analysis and estimation: A survey. Machine Learning, 113(5), pp.2351-2403.</li>
<li>How to access: https://arxiv.org/abs/2212.04612</li>
</ul>
<p>This piece will represent a large jump from reading about high-level frameworks that consider social factors, incentives, etc. to a much more mathematical framework for thinking about data-centricity. Accordingly, we&rsquo;re going to work through this piece (and some excerpts from the key citations) fairly slowly. For this week, you should just read pages 1-10 (on the arxiv version &ndash; up to Section 4).</p>
<p>For this week&rsquo;s reading responses, you do not need to answer any questions. Instead, please use the reading response as a chance to record any questions that come up (if you want to just ask them in lecture, that&rsquo;s great too!)</p>
<h2 id="week-6">Week 6</h2>
<p>This week we will continue reading the Hammoudeh and Lowd survey.</p>
<p>Please read pages 10-21 (up to Section 5.1.2, &ldquo;Representer Point Methods&rdquo;).</p>
<p>For your response, please answer the following 3 questions:</p>
<p>Q1) Please describe the difference between a leave one out influence value and a Shapley value, in the context of training data influence.</p>
<p>Q2) What is the main issue with calculating retraining-based data values, as described in our reading?</p>
<p>Q3) If you were asked to run a new data market that makes use of influence estimates, which approach from the reading would you use and why? There is no correct answer to question, but you should aim to think through some of the trade-offs.</p>
<h2 id="week-7-reading-week">Week 7 (Reading Week)</h2>
<p>This week, please read: </p>
<ul>
<li>Citation: Hestness, J., Narang, S., Ardalani, N., Diamos, G., Jun, H., Kianinejad, H., Patwary, M.M.A., Yang, Y. and Zhou, Y., 2017. Deep learning scaling is predictable, empirically. arXiv preprint arXiv:1712.00409.</li>
<li>How to access: https://arxiv.org/pdf/1712.00409.pdf</li>
</ul>
<p>For your response, please answer the following 3 questions:</p>
<p>Q1) Please describe the consistent finding across all ML domains in this study.</p>
<p>Q2) What are the three &ldquo;learning regions&rdquo; that the authors identify?</p>
<p>Q3) About how long did this reading take?</p>
<p>The reading response for this week will be due Week 8 (i.e., two responses due Week 8!)</p>
<h2 id="week-8">Week 8</h2>
<p>This week, we&rsquo;re going to start talking about online platforms and their role a key AI training data source. We&rsquo;ll orient much of our discussion around recent advances in Large Language Models, but with the caveat that the core ideas are equally relevant to search, recommendation, and classification systems in many applied domains of interest to our class (e.g. medicine, analytics for sports and games).</p>
<p>First, please read these two short blog posts from 2020 and 2022.</p>
<ul>
<li>https://dataleverage.substack.com/p/dont-give-openai-all-the-credit-for</li>
<li>https://dataleverage.substack.com/p/chatgpt-is-awesome-and-scary-you-deserve-credit</li>
</ul>
<p>Next, please read Sections 1 and 2 of this pre-print paper:</p>
<ul>
<li>https://arxiv.org/abs/2101.00027</li>
</ul>
<p>For this week, please list three specific online platforms that are useful for AI training.</p>
<h2 id="week-9">Week 9</h2>
<p>TBA</p>
<h2 id="week-10">Week 10</h2>
<p>TBA </p>
<h2 id="week-11">Week 11</h2>
<p>TBA</p>
<h2 id="week-12">Week 12</h2>
<p>TBAx</p>
</section>
<section id="readings-Optional_Classics" class="page-section ">
<h1>Optional Classics</h1>
<p>This file will contains the opposite of late breaking links: these are links to writing that we can consider &ldquo;classics&rdquo; in AI, HCI, and other fields.</p>
<p>(These are super opinionated, and very much incomplete.)</p>
<p>Early computing and AI:</p>
<p><a href="https://en.wikipedia.org/wiki/Vannevar_Bush">Vannevar Bush</a></p>
<ul>
<li><a href="https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">As We May Think</a>. 1945.</li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Norbert_Wiener">Norbert Wiener</a></p>
<ul>
<li>Cybernetics: Or Control and Communication in the Animal and the Machine. 1948.</li>
<li>The Human Use of Human Beings. 1950.</li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Herbert_A._Simon">Herbert Simon</a>:</p>
<ul>
<li>The Sciences of the Artificial. 1969.</li>
<li>Foundational concepts: Bounded rationality, Satisficing</li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Lucy_Suchman">Lucy Suchman</a></p>
<ul>
<li>&ldquo;Plans and Situated Actions&rdquo; (1987) - Influential critique of AI planning</li>
</ul>
<p>Philosophy:</p>
<p><a href="https://en.wikipedia.org/wiki/John_Rawls">John Rawls</a></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/A_Theory_of_Justice">A Theory of Justice</a>, 1971.<ul>
<li>Thinking sometimes shows up in fairness in AI discussions</li>
</ul>
</li>
</ul>
<p>Particularly influential economists who wrote about economics of information and knowledge:</p>
<p><a href="https://en.wikipedia.org/wiki/Friedrich_Hayek">Friedrich Hayek</a></p>
<ul>
<li><a href="https://www.jstor.org/stable/2548786">Economics and Knowledge</a>. 1937.</li>
<li><a href="https://www.econlib.org/library/Essays/hykKnw.html">The Use of Knowledge in Society</a>. 1945.</li>
<li>See also <a href="https://en.wikipedia.org/wiki/Socialist_calculation_debate">the Wikipedia article on the &ldquo;Socialist Calculation Debate&rdquo;</a> and discussion in the context of modern AI <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5054402">here</a></li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a></p>
<ul>
<li><a href="https://www.nber.org/system/files/chapters/c2144/c2144.pdf">Economic Welfare and the Allocation of Resources for Invention</a></li>
</ul>
<p>This <a href="https://en.wikipedia.org/wiki/Information_asymmetry">Wikipedia article</a> has many more works from economics that may be of interest and/or relevant ot a problem you&rsquo;ll face in the future.</p>
</section>
<section id="readings-Optional_LateBreaking" class="page-section ">
<h1>Optional Latebreaking</h1>
<p>This is a file where I&rsquo;ll record &ldquo;late breaking links&rdquo; &ndash; things that we (the class!) find via news, social media, our friends, etc.</p>
<h2 id="week-1">Week 1</h2>
<hr />
<p>An excellent post about programming with LLMs: https://crawshaw.io/blog/programming-with-llms</p>
<hr />
<h2 id="week-2">Week 2</h2>
<hr />
<p>An academic position paper on data-centric AI: https://aclanthology.org/2024.findings-emnlp.695/. Most relevant to Module 1.</p>
<details>
<summary> BibTex </summary>
@inproceedings{xu-etal-2024-position,
    title = "Position Paper: Data-Centric {AI} in the Age of Large Language Models",
    author = "Xu, Xinyi  and
      Wu, Zhaoxuan  and
      Qiao, Rui  and
      Verma, Arun  and
      Shu, Yao  and
      Wang, Jingtan  and
      Niu, Xinyuan  and
      He, Zhenfeng  and
      Chen, Jiangwei  and
      Zhou, Zijian  and
      Lau, Gregory Kang Ruey  and
      Dao, Hieu  and
      Agussurja, Lucas  and
      Sim, Rachael Hwee Ling  and
      Lin, Xiaoqiang  and
      Hu, Wenyang  and
      Dai, Zhongxiang  and
      Koh, Pang Wei  and
      Low, Bryan Kian Hsiang",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.695/",
    doi = "10.18653/v1/2024.findings-emnlp.695",
    pages = "11895--11913",
    abstract = "This position paper proposes a data-centric viewpoint of AI research, focusing on large language models (LLMs). We start by making a key observation that data is instrumental in the developmental (e.g., pretraining and fine-tuning) and inferential stages (e.g., in-context learning) of LLMs, and advocate that data-centric research should receive more attention from the community. We identify four specific scenarios centered around data, covering data-centric benchmarks and data curation, data attribution, knowledge transfer, and inference contextualization. In each scenario, we underscore the importance of data, highlight promising research directions, and articulate the potential impacts on the research community and, where applicable, the society as a whole. For instance, we advocate for a suite of data-centric benchmarks tailored to the scale and complexity of data for LLMs. These benchmarks can be used to develop new data curation methods and document research efforts and results, which can help promote openness and transparency in AI and LLM research."
}

</details>

<hr />
<p>Zhang et al. 2024, New survey on data markets: https://arxiv.org/abs/2411.07267. Most relevant to Module 4.</p>
<details> 
<summary> BibTex </summary>
@article{zhang2024survey,
  title={A Survey on Data Markets},
  author={Zhang, Jiayao and Bi, Yuran and Cheng, Mengye and Liu, Jinfei and Ren, Kui and Sun, Qiheng and Wu, Yihang and Cao, Yang and Fernandez, Raul Castro and Xu, Haifeng and others},
  journal={arXiv preprint arXiv:2411.07267},
  year={2024}
}
</details>

<p>Henderson and Lemley 2024, on AI Terms of Use: https://arxiv.org/abs/2412.07066. Most relevant to Module 4.</p>
<hr />
<details> 
<summary> BibTex </summary>
@misc{henderson2024mirageartificialintelligenceterms,
      title={The Mirage of Artificial Intelligence Terms of Use Restrictions}, 
      author={Peter Henderson and Mark A. Lemley},
      year={2024},
      eprint={2412.07066},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2412.07066}, 
}
</details>

<hr />
<p>The &ldquo;People&rsquo;s Capitalism Project&rdquo;: https://www.peoplescapitalism.org/. Most relevant to Module 4.</p>
<hr />
<p>Documents from Kadrey vs. Meta (tons of interesting data-centric insights into llama training): https://www.courtlistener.com/docket/67569326/kadrey-v-meta-platforms-inc/?page=3</p>
<hr />
<p>Some recent policy-related docs: OpenAI&rsquo;s economic blueprint: https://openai.com/global-affairs/openais-economic-blueprint/ and UK AI Opportunities Plan: https://www.gov.uk/government/publications/ai-opportunities-action-plan/ai-opportunities-action-plan</p>
<h2 id="week-3">Week 3</h2>
<p>https://s.mirror.xyz/djByMntM2rQF4tqUISYS2MAO3oCfSWoOZSOpZjsYwaw</p>
<h2 id="week-4">Week 4</h2>
<p>https://gradual-disempowerment.ai/</p>
<h2 id="week-5">Week 5</h2>
<p>https://ieeexplore.ieee.org/document/5197422</p>
<p>https://arxiv.org/abs/2501.18887</p>
<p>https://github.com/google-research/tuning_playbook</p>
</section>
<section id="readings-Readings_TLDR" class="page-section ">
<h1>Readings Tldr</h1>
<p>This file contains the bare minimum info about the readings: links and special instructions (e.g. just read the first x pages). You&rsquo;ll eventually need to read the longer doc to get the response instructions.</p>
<h2 id="week-2">Week 2</h2>
<ul>
<li>https://cacm.acm.org/magazines/2023/3/270209-toward-practices-for-human-centered-machine-learning/fulltext</li>
<li>https://arxiv.org/abs/2207.10062, just read the intro</li>
</ul>
<h2 id="week-3">Week 3</h2>
<ul>
<li>https://arxiv.org/abs/2002.04087</li>
<li>https://research.google/pubs/everyone-wants-to-do-the-model-work-not-the-data-work-data-cascades-in-high-stakes-ai/</li>
<li>https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch106</li>
</ul>
<h2 id="week-4">Week 4</h2>
<ul>
<li>https://fairmlbook.org/introduction.html</li>
<li>https://dl.acm.org/doi/10.1145/3274463, just read the intro</li>
</ul>
<h2 id="week-5">Week 5</h2>
<ul>
<li>https://arxiv.org/abs/2212.04612, p1-10</li>
</ul>
<h2 id="week-6">Week 6</h2>
<ul>
<li>https://arxiv.org/abs/2212.04612, p10-21</li>
</ul>
<h2 id="week-7">Week 7</h2>
<ul>
<li>https://arxiv.org/pdf/1712.00409.pdf</li>
</ul>
<h2 id="week-8">Week 8</h2>
<ul>
<li>https://dataleverage.substack.com/p/dont-give-openai-all-the-credit-for</li>
<li>https://dataleverage.substack.com/p/chatgpt-is-awesome-and-scary-you-deserve-credit</li>
<li>https://arxiv.org/abs/2101.00027, Sections 1 and 2.</li>
</ul>
</section>
<section id="assignments-assignment_1_tools" class="page-section ">
<h1>Assignment 1 Tools</h1>
<p>You will submit a short report on your tool-related exploration as your first &ldquo;coding assignment&rdquo;.</p>
<p>You don&rsquo;t need to submit any particular code, but after you&rsquo;ve completed this report you&rsquo;re encouraged to try out a &ldquo;practice run&rdquo; with the tools you&rsquo;ve selected. For instance, you might try spending 30-60 minutes on a quick &ldquo;side project&rdquo;, and make sure you&rsquo;re able to complete it, produce an output file, etc.</p>
<p>After you’ve spent some time exploring tools, please submit via Canvas a report which describes your answers to the following questions. You can submit as a PDF file or in plaintext as a .md file. Please organize your answers in terms of question numbers, as indicated below. It’s perfectly OK if some of your answers are very short!</p>
<p>Your choices are not binding &ndash; this primarily to get you thinking about these choices early on and to encourage you to explore some of the available options before additional assignments are due.</p>
<p>Q1: Which tools you plan to use for writing code (IDE, AI assistance, version control). e.g. answers might include: VS Code, Sublime text, ChatGPT, Copilot, GitHub</p>
<p>Q2: What open questions or concerns do you have about code writing tools?</p>
<p>Q3: Which ML libraries / frameworks / tools do you have familiarity with already?</p>
<p>Q4: If given the choice, which ML libraries do you prefer to use for any assignments that involve training and evaluating a ML model?</p>
<p>Q5: Which ML libraries / frameworks / tools do you hope to learn more about (“I’m not sure, that’s why I’m taking this class” is an OK answer!)</p>
<p>Q6: Which tools you plan to use to read and take notes on papers, if any (pen + paper or PDF reader + notes app is perfectly fine answer!)</p>
<p>Q7: Which tools, if any, you plan to use for project management?</p>
</section>
<section id="assignments-assignment_2_influence" class="page-section ">
<h1>Assignment 2 Influence</h1>
<h1 id="assignment-2">Assignment 2</h1>
<p>Our Module 2 content is focused on understanding the broad question: <em>Which groups of observations – or groups of people – are “responsible” for a given model output or “capability”?</em></p>
<p>In this assignment, we&rsquo;ll get some hands-on experience with the concept of training data influence.</p>
<p>There are four parts to the assignment. You&rsquo;ll need to write code to train a ML model and produce influence values for some of the training data in the model. Below, the requirements for each part are described.</p>
<p>Each part will have a coding component and a report component. You will turn in one file (or multiple) with code (e.g., a `.py` file or `.ipynb` file) and one report PDF. If using computational notebooks like a Jupyter notebook, you may combine these two into a single file (e.g. a notebook exported to a PDF with code visible.</p>
<p>In your code, you can use comments to designate which parts of your code correspond to each part.</p>
<p>Note 1: you may work on this assignment in groups of 1-3.</p>
<p>Note 2: you may use generative AI on this assignment, and must report your use. FYI – the instructor has tried out several models, and they’re definitely useful, but you’ll need to be careful about explaining your choices. In fact, I’ll even provide you some example outputs of what you get from directly copy-pasting the assignment into several strong models!</p>
<p>Note 3: Finally, as an additional incentive to avoid literally just copy-pasting the assignment in your favorite consumer AI product, I may randomly select some students to explain their solutions in class.</p>
<h3 id="part-1-preliminaries"><strong>Part 1: Preliminaries</strong></h3>
<p>First, you should select a dataset to work with, define a specific classification (must do classification for this assignment) task, and establish a baseline model.</p>
<p>If you&rsquo;re looking for inspiration, you might consider selecting something from <a href="https://archive.ics.uci.edu/">https://archive.ics.uci.edu/</a></p>
<p>You will not be graded based on your dataset choice, task choice, or achieving a certain level of performance.</p>
<p>Rather, you will be graded based on your ability to describe, in a scientifically complete fashion, the choices you&rsquo;ve made.</p>
<p>You are recommended to select a dataset from a domain of your interest and then take a small random sample of that dataset (e.g., 10000 rows &ndash; though you can lower this if using high-dimensional data, want to use deep learning, etc. &ndash; ask us if you&rsquo;re unsure) to ensure that you can complete this assignment quickly, without being burdened by excessive computational costs. What constitutes &ldquo;excessive&rdquo; here will depend on your access to computing resources (you may wish to explore using an online tool with some degree of free compute like Google Colab).</p>
<p>If you select a dataset you are interested in, you may be able to reuse some of your code you write for this assignment for your project.</p>
<p>Suggested approach: I recommend first training several models on the &ldquo;full dataset&rdquo; (e.g. logistic regression, basic random forest, KNN, XGBoost). See how long this takes. Then, try subsampling 10% or 1% of your data and see if the training time falls low enough that you think you can reasonably retrain a model at least 50 total times.</p>
<p>Specifically, you should write code to do the following:</p>
<ul>
<li>Load a dataset into memory. Describe the dataset in your report. (2 marks)  </li>
<li>Process into features and labels. Describe the features and labels in your report. (2 marks)  </li>
<li>Split into train and test sets. Describe your specific approach (e.g. random 80/20 split, time-based split, etc.) (2 marks)  </li>
<li>Train some classifier. It does not need to be the &ldquo;best&rdquo; possible performance for your chosen dataset, though you may want to try a few options if feasible to do so. (2 marks)  </li>
<li>Report performance of your baseline classifier: accuracy, confusion matrix. You are encouraged to include a precision-recall curve or TPR vs. FPR curve (i.e. AUROC curve), though if you think it isn&rsquo;t helpful you can just mention why not. You must choose a &ldquo;primary metric&rdquo; that you will use for your data value estimates, and you should briefly justify this choice. (2 marks)</li>
</ul>
<p>10 marks total for part 1</p>
<h3 id="part-2-brute-force-loo-influence"><strong>Part 2: Brute force LOO influence</strong></h3>
<p>Next, you should select (manually or randomly) 10 training data points (i.e., observations) and compute the exact leave-one-out LOO influence of these examples on your chosen primary metric.</p>
<p>You can earn up to 4 marks for clean and correct code.</p>
<p>Report the influence score for each of your observations. You may do this in a table or plot. (2 marks).</p>
<p>Please briefly comment on any trends you observe with your influence scores. Are any points with high influence unusual in any way? It&rsquo;s OK if they&rsquo;re not, but you should demonstrate that you looked. (2 marks)</p>
<p>8 marks total for part 2.</p>
<h3 id="part-3-group-level-influence"><strong>Part 3: Group-level influence</strong></h3>
<p>Next, you should select (manually or randomly) 10 different <em>groups</em> of data points of different sizes. For instance, you might randomly select 10%, 20%, 30%, etc. of the training data. You should compute the exact leave-entire-group-out influence for each group.</p>
<p>You can earn up to 4 marks for clean and correct code.</p>
<p>Report the influence score for each of your groups. (2 marks)</p>
<p>For part 3, you must also include a plot that shows group size compared with influence. (2 marks)</p>
<p>8 marks total for part 3.</p>
<h3 id="part-4-shapley-values"><strong>Part 4: Shapley values</strong></h3>
<p>Finally, we will roughly estimate Shapley values for our training data.</p>
<p>For each observation and each group, you should compute the Shapley value using Truncated Monte Carlo Shapley Value Estimation (described briefly in our survey reading and in more detail here: <a href="http://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf">http://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf</a>).</p>
<p>This will involve a coding challenge: implementing this particular Shapley value estimation algorithm.</p>
<p>In the Ghorbani and Zou paper, the authors suggest using a truncation cut-off: if performance for a given point / time step is very close to full performance V(D), we don&rsquo;t need to retrain again.</p>
<p>We will go a step further and use the following rule to ensure our code doesn&rsquo;t take too long to run: we should take our best guess at the Shapley value for each training data point after only 10 total permutations have been examined. In other words, your code should just re-shuffle the training data 10 times, compute the marginal impact of each training point, and then average these across the 10 permutations.</p>
<p>Furthermore, you may further subsample your training data (E.g. if you started with 100k rows and have only been using 10k so far, and need to drop down to 1k&hellip; you can) for this part if needed to complete the assignment in time.</p>
<p>You can earn up to 4 marks for clean and correct code.</p>
<p>Here, you need only to plot the distribution of all Shapley values. (2 marks)</p>
<p>If you have extra time, you are encouraged to compute more accurate Shapley value estimates by using more permutations and compare the Shapley values to LOO influence from part 2, but this is optional.</p>
<p>6 marks total for part 4.</p>
<h3 id="grading"><strong>Grading</strong></h3>
<p>This assignment will be graded based on both code correctness and an accompanying report. You can earn marks for each of these separately (i.e. if you have errors in your influence calculations, you can still earn the marks for reporting and visualizing the potentially erroneous data values).</p>
<p>To recap, there are:</p>
<ul>
<li>10 marks available in part 1  </li>
<li>8 in part 2  </li>
<li>8 in part 3  </li>
<li>6 in part 4  </li>
<li>for a total of 32 marks.</li>
</ul>
<p>Part 4 will likely be the most difficult, but offers the least marks, so you should consider completing the earlier sections first.</p>
<p>If you submitted with a group, your report must include a &lsquo;contribution statement&rsquo; that describes how each member contributed.</p>
</section>
<section id="assignments-project_proposal" class="page-section ">
<h1>Project Proposal</h1>
<h2 id="project-proposal">Project Proposal</h2>
<p>We&rsquo;re going to start thinking about our projects relatively early in the term! To scaffold the project ideation, you&rsquo;ll be asked to turn in an initial <strong>project proposal</strong> on Feb 26.</p>
<p>You can submit a 1-2 page PDF, text, or Markdown file. Exact length is not critical here: as long as it contains the key ideas, you&rsquo;re good to go.</p>
<p>This proposal is not binding, though you will earn some marks for turning it in. You can change your project topic, track, or group after the proposal is submitted (though you&rsquo;re encouraged to stick relatively close to your proposal, just for the sake of your own time).</p>
<p>For the project, you can select from three tracks, described below.</p>
<p>Well before you turn your project in, you will be provided with a much more detailed rubric describing how your project will be graded. For the initial proposal, however, you should just focus on selecting a project that:</p>
<ul>
<li>fits your personal interests in the course (including your career goals)</li>
<li>will give you an opportunity to explore and demonstrate understanding of the key concepts from our readings and lectures.</li>
</ul>
<p>The two heuristic questions I recommend you ask while brainstorming project ideas:</p>
<ul>
<li>Does this project meet the unique individual incentives of all group members (e.g., a chance to work with a particular ML library, a chance to work on a task of interest, a chance to produce a high quality report or prototype to include in my portfolio).</li>
<li>Does this project offer an opportunity to demonstrate understanding of key concepts from the course? For instance, does it fit into any of the frameworks for human-centered ML and AI that we&rsquo;ve seen, or does it relate to any of the calls for data-centric we&rsquo;ve seen?</li>
</ul>
<h3 id="track-1-tools-and-interfaces-for-humandata-centered-ai"><strong>Track 1: Tools and interfaces for human/data-centered AI</strong></h3>
<p>Track 1 will be a good fit for front-end focused projects. For this track, you can propose and develop some kind of tool or interface for data-centric AI. This interface might be a web application, mobile application, or even a user-focused CLI prototype.</p>
<p>To fit the project criteria, this tool should help users accomplish some kind of data-related action or some kind of data exploration task. In other words, it should either be targeted at users who want to control the flow of their data, or at data scientists who want to explore data in some way.</p>
<p>Please note that if you&rsquo;re very uncomfortable doing prototyping and frontend development, you may not want to select this track. While I&rsquo;m happy to support you if you want to learn these topics on the fly, we probably won&rsquo;t have much time to cover core design, frontend, or software engineering concepts in this course, so this project is best suited to students who already have some of those skills and specifically want to use their project work time to advance in this area.</p>
<p>Examples:</p>
<ul>
<li>A new interface for interacting with large language models that allows user to save or export conversation data (you might consider forking and contributing to something like<a href="https://github.com/ollama-webui/ollama-webui"> https://github.com/ollama-webui/ollama-webui</a>)</li>
<li>A browser extension that helpers user collect and use data generated by their own browsing (e.g. export my YouTube watch history and train a local personalization / recommender system)</li>
<li>A browser extension that blocks data collection and informs the user how data that&rsquo;s collected might impact AI systems</li>
<li>A web interface for visually exploring aspects of a dataset, aimed at ML developers</li>
</ul>
<h3 id="track-2-ml-project-with-data-exploration-component"><strong>Track 2: ML Project with Data Exploration Component</strong></h3>
<p>Track 2 will be the closest to what you might do in a typical project-focused ML course. For this project, you should select a machine learning task of interest and produce a thorough report describing how you might tackle the relevant ML challenges. What will set your project apart from a pure ML focused course is that you will also be asked to conduct a data-centric exploration of the task. This might involve using data valuation techniques we learned in the course, exploring different dataset selection choices, etc.</p>
<p>The DataPerf reading will be particularly useful to projects on this track.</p>
<p>Examples:</p>
<ul>
<li>You might select a medical imaging dataset from a research lab or research challenge and show how selecting or deselecting certain training observations impact performance on a carefully chosen held out test set</li>
<li>You might fine-tune an open language model with a variety of different fine-tuning sets and explore the impact on benchmark performance or quality as perceived by humans</li>
</ul>
<h3 id="track-3-dataset-documentation-and-ai-auditing"><strong>Track 3: Dataset Documentation and AI Auditing</strong></h3>
<p>Later in the course, we will discuss some research on dataset documentation and AI auditing. To summarize, this work involves carefully scrutinizing existing datasets and/or the outputs of AI systems to check for potential biases, performance gaps, unusual behavior, etc.</p>
<p>As your project, you might pick a famous dataset or AI system and conduct a systematic documentation effort or &ldquo;audit&rdquo;.</p>
<p>Examples:</p>
<ul>
<li>You might select a popular dataset that&rsquo;s been used to train LLMs like ChatGPT and use a mix of manual inspection and ML-powered investigation to try and understand the demographics of dataset contributors, or biases in the underlying the content.</li>
<li>A fun example of this might involve a question like, &ldquo;How much do various fandom communities discussing their favorite movie, book, anime, etc.&rdquo; contribute to the success of ChatGPT?</li>
</ul>
<p>If you wish to pursue this option, please consult with the instructor first to discuss properly scoping this kind of project (obviously, investigating every single piece of training data underlying ChatGPT will not be possible with the time we have).</p>
<p>References:</p>
<ul>
<li>BookCorpus datasheet:<a href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pdf"> https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/54229abfcfa5649e7003b83dd4755294-Paper-round1.pd</a></li>
<li>Mozilla&rsquo;s Common Crawl data investigation:<a href="https://foundation.mozilla.org/en/blog/Mozilla-Report-How-Common-Crawl-Data-Infrastructure-Shaped-the-Battle-Royale-over-Generative-AI/"> https://foundation.mozilla.org/en/blog/Mozilla-Report-How-Common-Crawl-Data-Infrastructure-Shaped-the-Battle-Royale-over-Generative-AI/</a></li>
</ul>
<h3 id="mixing-the-tracks"><strong>Mixing the tracks</strong></h3>
<p>If you have an idea for a project that involves mixing multiple tracks, that is totally great! Please let us know via the initial proposal draft.</p>
<p>In particular, mixing tracks might make sense if you have a larger group of students who want to work on multiple parts of a particular problem. For instance, if you want to build a prototype system that hooks up with a ML model and reports the results of a dataset documentation effort, you can definitely do so.</p>
</section>
<section id="assignments-project_rubric" class="page-section ">
<h1>Project Rubric</h1>
<h1 id="project-rubric-draft-tentative-as-of-jan-28">Project Rubric - DRAFT, TENTATIVE AS OF JAN 28</h1>
<p>Here, you will find detailed instructions for the class project.</p>
<p>This document assumes you&rsquo;ve read the details in the Project Proposal.</p>
<h3 id="when-is-the-project-due"><strong>When is the project due?</strong></h3>
<p>The official project deadline is <strong>TBA</strong>.</p>
<p>You are encouraged to finish a draft of your project report before the end of the semester. You will have an opportunity to present your project. This is voluntarily but operates under the &ldquo;it can only help you&rdquo; rule: if your presentation helps to clarify the contributions or challenges of your project, this may positively affect your grade. In particular, presenting your project can help you increase your &ldquo;relevance to class themes&rdquo; score, as I will ask questions and give you a chance to further demonstrate engagement with our key themes.</p>
<p>If you believe you can make major improvements with some extra time, you can write an &ldquo;extension&rdquo; plan <strong>at least a week in advance</strong> (detailing how your group will use the following time (between 1-5 days). This should be structured much like an email or presentation you might give your boss explaining why a feature needs an extra week of dev time (something that may happen in your career!)</p>
<h3 id="how-is-the-class-project-graded"><strong>How is the class project graded?</strong></h3>
<p>Group-based scaling: I&rsquo;ve mentioned in class that larger groups will have higher overall expectations for what the project accomplishes.</p>
<p>In practice, this will be implemented based on an assessment of &ldquo;overall contribution&rdquo; and based on your report&rsquo;s &ldquo;contribution statements&rdquo;. You should describe what everyone did and provide evidence that everyone did something. When I assess your output artifact, I will write a “contribution summary” myself with <em>my understanding</em> of what everyone did. If your artifact lacks the details for me to do this, you will lose marks!</p>
<p>More concretely, we will use the following rubric/process to assign grades to the projects. Remember that a goal of the highly flexible project &ldquo;tracks&rdquo; is so that you can make something that will look good on your portfolio based on your own career or personal interests. This will be a motivating theme in grading -- could the project impress a potential employer? Will I be excited to share your output artifacts with my colleagues?</p>
<p>You are expected to do some degree of self or collaborative learning as part of the project. You may need to try out libraries we didn&rsquo;t use directly during class time or read work that wasn&rsquo;t assigned. If you are <em>only</em> engaging with strictly required course materials, this is enough for our quizzes, but probably not be enough for the project.</p>
<h4 id="report-rubric"><strong>Report Rubric</strong></h4>
<p>You will submit a report, which will be structured much like an academic paper.</p>
<p>This includes the following components</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Abstract</th>
<th style="text-align: left;">2 points (5%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Visual Abstract</td>
<td style="text-align: left;">2 points (5%)</td>
</tr>
<tr>
<td style="text-align: left;">Introduction</td>
<td style="text-align: left;">4 points</td>
</tr>
<tr>
<td style="text-align: left;">Related Work</td>
<td style="text-align: left;">4 points</td>
</tr>
<tr>
<td style="text-align: left;">Methods</td>
<td style="text-align: left;">4 points</td>
</tr>
<tr>
<td style="text-align: left;">Results</td>
<td style="text-align: left;">4 points</td>
</tr>
<tr>
<td style="text-align: left;">Discussion</td>
<td style="text-align: left;">8 points</td>
</tr>
<tr>
<td style="text-align: left;">Connection to class themes</td>
<td style="text-align: left;">4 points</td>
</tr>
<tr>
<td style="text-align: left;">Overall artifact quality</td>
<td style="text-align: left;">8 points</td>
</tr>
</tbody>
</table>
<p>Total: 40 points</p>
<p>The marking for the report component will be organized as follows (roughly following the structure of many of our readings):</p>
<p><strong>Abstract: 2 points</strong></p>
<p>Summarize the key contribution of your project. It should be understandable to all of your classmates, and at least partially understandable to your peers from across a variety of disciplines.</p>
<p>Marking scheme: 2/2 for clear concise project that explains what your project does and why you were motivated to do it. 1/2 for an abstract that is difficult to read, is vague, or doesn&rsquo;t motivate the work. 0/3 for an abstract that is very vague.</p>
<p><strong>Visual Abstract: 2 points</strong></p>
<p>Create a figure or diagram that summarizes the key contribution of your project.</p>
<p>Same marking scheme as abstract.</p>
<p><strong>Introduction: 4 points</strong></p>
<p>State the problem your project solves, which might mean answering a research question (Track 1), providing some value to users (Track 2), or answering a dataset documentation question (Track 3). You should cite some motivating work and situate your project disciplinarily. Who is your audience? You should look at the Introductions of the research papers we read in class to get a sense of the appropriate style and tone. If in doubt, you can explicitly cite your “exemplar papers”.</p>
<p>Your introduction should also concisely state what your main contributions are. What did you do – did you perform experiments, or conduct a literature review?</p>
<p>Marking scheme: 2 points for clear problem statement. 2 points for a clear high-level description of your main contribution (from the Introduction, I should have a general sense of what you did, and I’ll get the details in Methods).</p>
<p><strong>Related work: 4 points</strong></p>
<p>You should conduct a reasonable literature review of related work. You may want to make use of tools like Google Scholar and Semantic Scholar. This does not need to be restricted to peer-reviewed academic works or class readings. You can, and should, cite anything that helped you work on the project or serves as a point of comparison, including software libraries on GitHub, pre-prints on arXiv, blog posts from ML researchers, etc. You should be able to find 3-4 references that you engage with closely, at least one of which is an academic work and itself provides upstream / &ldquo;classics&rdquo; in the subfield of your choice. </p>
<p>Marking scheme:</p>
<p><strong>Methods / What you did: 4 points</strong></p>
<p>You should describe what you did. You are encouraged to find and cite an exemplar paper in order to help you structure your Methods section.</p>
<p>This section will vary heavily amongst different project types.</p>
<p>If you are unable to find an exemplar paper, please let me know!</p>
<p>Marking scheme: </p>
<ul>
<li>2 points for a clear description of what you did and justification for it.  <ul>
<li>e.g. just saying “I used sklearn” will not earn marks – you should specify the model you used, how you selected hyperparameters, etc.  </li>
<li>e.g. just saying “I select this model because it’s popular” will not earn marks – you should specify the criteria you considered for selecting a model  </li>
</ul>
</li>
<li>2 points for appropriateness of methods choice</li>
</ul>
<p><strong>Results / What you produced: 4 points</strong></p>
<p>This section will also vary quite a bit based on your project. You are encouraged to find and cite an exemplar paper here, as well.</p>
<p>Marking scheme: </p>
<ul>
<li>“Results” will vary heavily, so this rubric will lend most to the “simulated reviewer” approach. Your results section should aim to “fulfill the promise” of your methods. If you said you will use a particular evaluation approach, you should provide the relevant data here and describe the insights from that data.  </li>
<li>For this section in particular, you may send in any early draft if you’re unclear about whether you need to get “more” results.</li>
</ul>
<p><strong>Discussion: 8 points</strong></p>
<p>You can earn up to 8 points for discussing the implications of your project and especially potential lines of future work that incorporate a data-centric or human-centric lens. This section has a large point total because it is your change to show your engagement with course materials and concepts. You do not need to <em>only</em> discuss course readings or quote from course materials, but to earn a high score you should demonstrate engagement with course themes. </p>
<p>Here, you are welcome to disagree with course materials. Perhaps your project results have tension with claims made in our readings. If so, you can describe them here (this is one aspect of your project report that you may wish to edit before sharing, as this “disagreement” may make less sense outside of the course project).</p>
<p>Marking scheme: </p>
<ul>
<li>8 points for extremely in depth engagement – your writing here suggests you have deeply understood and considered key ideas from our readings and discussions, and were able to apply these effectively to concrete context  <ul>
<li>E.g. you highlight benefits (or challenges!) that arise from applying abstract concepts in our readings to a real application area. Your discussion section would be a great starting point for a research publication or for a blog post about your software.  </li>
</ul>
</li>
<li>6 points for good level of engagement  <ul>
<li>E.g., It is obvious you have done the course readings, but some discussion points may be unconvincing or shoehorned in.  </li>
</ul>
</li>
<li>4 points for reasonable engagement  <ul>
<li>E.g.. You cite HCML and an online platforms-related reading and mainly summarize some points from those articles  </li>
</ul>
</li>
<li>2 points for last ditch effort  <ul>
<li>E.g., You throw together a paragraph or two that mention human and data-centric AI, but I am not convinced you can describe key concepts.</li>
</ul>
</li>
</ul>
<p><strong>Connection to class themes: 4 points</strong></p>
<p>Between 0 and 4 points. Outside of your discussion, does your project show engagement with some of the frameworks for thinking we&rsquo;ve discussed in the class? If I saw this project in your portfolio, would it give me confidence in your ability to work on &ldquo;human-centered&rdquo; or &ldquo;data-centered&rdquo; projects?</p>
<p>Marking scheme:</p>
<ul>
<li>If you have discussed this with me before, you should earn 4 marks for this category.  </li>
<li>If not, I will mark on a scale of very connected \&lt;&gt; very much not connected</li>
</ul>
<p><strong>Overall artifact quality: 8 points</strong></p>
<p>You will also earn points for producing high quality artifacts -- this might be code, UI design mock-ups, an actual interface, or a very well formatted report.</p>
<p>You should include at the end of your report a contribution statement describing specifically how each group member contributed to each section of the project and each artifact.</p>
<p>You will also turn in (via zip file or web link) your project &ldquo;components&rdquo; (code, other artifacts, etc.). You are encouraged to create a public GitHub repository and just put the link in your report PDF. This will make it easier to share with others as well.</p>
<p>Marking scheme:</p>
<ul>
<li>8/8: a stunning artifact that I am thrilled to share with my colleagues  </li>
<li>4/4: decent effort. Not my first choice to show off to my colleagues.  </li>
<li>0/4: extremely low effort.</li>
</ul>
<p>Note that I don’t expect everyone to produce an 8/8 quality (nor do you need to: if you get 36/40 on your report, 90% on all quizzes, and 90% on all assignments, you will still easily get an </p>
<h3 id="what-do-i-turn-in"><strong>What do I turn in?</strong></h3>
<p>Required: a report as PDF.</p>
<p>Optional: include a web link to your project materials (e.g. a GitHub link).</p>
<p>Optional: include a zip file with project materials.</p>
<p>Optional: Present your project during the final week of class.</p>
</section>
<section id="misc-Key_Dates" class="page-section ">
<h1>Key Dates</h1>
<h1 id="week-6-onwards">Week 6 Onwards</h1>
<p>This document contains a summary of all remaining key dates for the rest of the term.</p>
<p>I&rsquo;ll also try to also clarify here the relevant Week Number and day of the week.</p>
<p>For our purposes, Mon Feb 10 begins &ldquo;Week 6&rdquo;. Week 7 begins Feb 17, but we have no class &ndash; it is &ldquo;consumed&rdquo; by Reading Week.</p>
<h2 id="key-dates-assignment-2-quiz-2-project-proposal-assignment-3-quiz-3">Key Dates (Assignment 2, Quiz 2, Project Proposal, Assignment 3, Quiz 3)</h2>
<ul>
<li>Assignment 2: Mar 4 11:59pm (Tuesday of Week 9. Class time to work on this on Feb 13)<ul>
<li>Aiming for 2 weeks of time to complete, not counting reading week.</li>
</ul>
</li>
<li>Quiz 2: Feb 27th 12:30pm (Thursday of Week 8. Assignment 2 should help you study for this, so don&rsquo;t leave it for the last minute).<ul>
<li>On paper, in class, first 30 mins. Make-up details TBA, please try not to miss it.</li>
</ul>
</li>
<li>Project proposal: Feb 28th 11:59pm (Friday of Week 8)<ul>
<li>CourSys.</li>
</ul>
</li>
<li>Assignment 3: tentatively due Mar 18 11:59pm. <ul>
<li>CourSys.</li>
</ul>
</li>
<li>Quiz 3: tentatively Mar 20, 12:30pm.</li>
<li>Project Report: April 3</li>
<li>Project presentations round 1: April 3.</li>
<li>Project presentation round 2: April 8.</li>
</ul>
<h2 id="reading-response">Reading Response</h2>
<p>We will continue to have reading responses.</p>
</section>
<section id="misc-Lecture_Erratum" class="page-section ">
<h1>Lecture Erratum</h1>
<p>&ldquo;An erratum or corrigendum (pl.: errata, corrigenda) (comes from Latin: errata corrige) is a correction of a published text&rdquo; (source: <a href="https://en.wikipedia.org/wiki/Erratum">Wikipedia</a>).</p>
<p>In this doc, I&rsquo;ll record any meaningful typos in materials or answers to questions to that may have caused confusion.</p>
<p>In Spring 2025, I started this doc on Feb 12</p>
<h2 id="week-6">Week 6</h2>
<ul>
<li>Feb 11<ul>
<li>Minor: Several typos in slides, see this <a href="https://github.com/nickmvincent/cmpt419_spring2025/commit/ff0bf6be48f78ccd355aacf92a53738f38cb506c">commit</a> if curious</li>
<li>Substantive: in lecture, my explanation of the denominator used when calculating Shapley values was a bit confusing. I compeltely reworked these slides to provide a clearer example where have 10 rows (n=10) and we consider all the &ldquo;coalitions&rdquo; of size 9, then of size 8, then of size 7&hellip;</li>
<li>Substantive: in lecture, I went very quickly when describing the desirable economic properties of the Shapley value. If curious (and especially if you might be taking or will take econ courses that use Shapley values, see e.g. <a href="https://en.wikipedia.org/wiki/Shapley_value">here</a>. I&rsquo;ll also revisit this with some examples on Thursday.)</li>
</ul>
</li>
</ul>
</section>
<section id="misc-Prerequisites_Doc" class="page-section ">
<h1>Prerequisites Doc</h1>
<p>There are no hard prerequisites for this course. The course outline says this:</p>
<p>Students may benefit from having taken a course in AI, ML, or data science (or have equivalent experience from e.g. an internship, a research project, a personal project).</p>
<p>Example SFU courses:<br />
- CMPT 310 - Intro Artificial Intelligence<br />
- CMPT 353 - Computational Data Science<br />
- CMPT 414 - Computer Vision</p>
<p>Having taken an HCI course or relevant social science course (e.g., sociology, economics) is a plus, but students without this experience who want to explore interdisciplinary CS work that is “human-centered” are welcome.</p>
<p>That being said, here are some materials that you can use to assess your readiness for the course. My suggestion is to take a look at the code first and see if it seems completely unfamiliar. If you&rsquo;ve taken CMPT 353, this will be very familiar. If this content is unfamiliar, you may want to glance through the sklearn tutorial (https://scikit-learn.org/1.4/tutorial/basic/tutorial.html), or for much for detail, the CMPT 353 lecture notes (https://ggbaker.ca/data-science/).</p>
<p>On the ML theory side of things, you may want to watch the 3Blue1Brown Deep Learning series and see if it seems completely unfamiliar or at least partially familiar: https://www.youtube.com/watch?v=aircAruvnKk</p>
<p>If at least one of these feels decently familiar and the other feels somewhat familiar, you&rsquo;re probably in good shape. We won&rsquo;t have any quiz questions in the course that are directly testing computational data science or deep learning material, but the concepts come up and you&rsquo;ll want to have some basis in one of these areas to develop a good project idea.</p>
<p>In terms of HCI or social science materials, we&rsquo;ll cover background in the course. Any and all perspectives are welcome!</p>
<p>You may also want to check out this ChatGPT-generated exercises below to see some examples of common operations machine learning operations.</p>
<pre><code class="language-python"># CRASH COURSE: Basic Model Training, Testing, and Data Analysis

# ===========================
# 1. IMPORT LIBRARIES
# ===========================
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.datasets import load_iris

# To display plots inline
%matplotlib inline

# ===========================
# 2. LOAD AND EXPLORE DATA
# ===========================
data = load_iris()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target, name='target')

print(&quot;First five rows of data:&quot;)
display(X.head())

print(&quot;Data shape:&quot;, X.shape)
print(&quot;Target shape:&quot;, y.shape)

print(&quot;\nClass distribution:&quot;)
print(y.value_counts())

# ===========================
# 3. BASIC DATA ANALYSIS
# ===========================
# Statistical summary
print(&quot;\nStatistical summary of features:&quot;)
display(X.describe())

# Pairplot for a quick visual
sns.pairplot(pd.concat([X, y], axis=1), hue='target', diag_kind='kde')
plt.show()

# ===========================
# 4. TRAIN-TEST SPLIT
# ===========================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(&quot;\nTraining set size:&quot;, X_train.shape)
print(&quot;Test set size:&quot;, X_test.shape)

# ===========================
# 5. MODEL TRAINING
# ===========================
model = LogisticRegression(max_iter=200)  # Increase max_iter to ensure convergence
model.fit(X_train, y_train)

# ===========================
# 6. MODEL TESTING &amp; EVALUATION
# ===========================
y_pred = model.predict(X_test)

# Classification report
print(&quot;\nClassification Report:&quot;)
print(classification_report(y_test, y_pred))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print(&quot;Confusion Matrix:\n&quot;, cm)

sns.heatmap(cm, annot=True, cmap=&quot;Blues&quot;, fmt=&quot;d&quot;, cbar=False)
plt.title(&quot;Confusion Matrix&quot;)
plt.xlabel(&quot;Predicted&quot;)
plt.ylabel(&quot;True&quot;)
plt.show()

# ===========================
# 7. EXERCISES FOR STUDENTS
# ===========================
print(&quot;&quot;&quot;
Exercises:
1. Try a different classifier (e.g., RandomForestClassifier) and compare results.
2. Experiment with different test sizes (e.g., test_size=0.3).
3. Visualize the coefficient importances or feature importances for your chosen model.
4. Use other performance metrics (e.g., accuracy_score, precision_score) for evaluation.
5. Analyze how class imbalance might affect results (if you artificially modify 'y').
&quot;&quot;&quot;)
</code></pre>
<pre><code class="language-python"># DEEP LEARNING CRASH COURSE

# ===========================
# 1. IMPORTS &amp; SETUP
# ===========================
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

%matplotlib inline

# ===========================
# 2. LOAD &amp; PREPARE MNIST
# ===========================
# The MNIST dataset has 60,000 training images, 10,000 test images
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to [0, 1]
x_train = x_train.astype(&quot;float32&quot;) / 255.
x_test  = x_test.astype(&quot;float32&quot;) / 255.

# Flatten 28x28 images to 784-dimensional vectors for the MLP
x_train_flat = x_train.reshape((x_train.shape[0], 28 * 28))
x_test_flat  = x_test.reshape((x_test.shape[0], 28 * 28))

# ===========================
# 3. BASIC DENSE MODEL
# ===========================
mlp_model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(784,)),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

mlp_model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# ===========================
# 4. TRAIN &amp; EVALUATE (MLP)
# ===========================
history_mlp = mlp_model.fit(
    x_train_flat, y_train,
    validation_split=0.1,
    epochs=5,
    batch_size=64,
    verbose=1
)

test_loss, test_acc = mlp_model.evaluate(x_test_flat, y_test)
print(f&quot;\nMLP Test accuracy: {test_acc:.4f}&quot;)

# Optional: Plot training curves
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history_mlp.history['loss'], label='Train Loss')
plt.plot(history_mlp.history['val_loss'], label='Val Loss')
plt.legend()
plt.title(&quot;MLP Loss&quot;)

plt.subplot(1,2,2)
plt.plot(history_mlp.history['accuracy'], label='Train Acc')
plt.plot(history_mlp.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title(&quot;MLP Accuracy&quot;)
plt.show()

# ===========================
# 5. ADVANCED SECTION: BASIC CNN
# ===========================
# Reshape data back to (28, 28, 1)
x_train_cnn = x_train.reshape((x_train.shape[0], 28, 28, 1))
x_test_cnn  = x_test.reshape((x_test.shape[0], 28, 28, 1))

cnn_model = keras.Sequential([
    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu',
                  input_shape=(28, 28, 1)),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.2),  # regularize
    layers.Dense(10, activation='softmax')
])

cnn_model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

history_cnn = cnn_model.fit(
    x_train_cnn, y_train,
    validation_split=0.1,
    epochs=5,
    batch_size=64,
    verbose=1
)

test_loss_cnn, test_acc_cnn = cnn_model.evaluate(x_test_cnn, y_test)
print(f&quot;\nCNN Test accuracy: {test_acc_cnn:.4f}&quot;)

# ===========================
# 6. EXERCISES FOR STUDENTS
# ===========================
print(&quot;&quot;&quot;
Exercises:
1. Increase the number of epochs or change batch_size and observe results.
2. Modify the architecture (add more layers/neurons) and see if it improves accuracy.
3. Try different optimizers (RMSprop, SGD) and compare training dynamics.
4. Add Batch Normalization layers to see if training stabilizes.
5. Explore other datasets (CIFAR-10, Fashion-MNIST) for a broader challenge.
&quot;&quot;&quot;)
</code></pre>
</section>
<section id="slides_pdfs-Week1-Part1" class="page-section ">
<h1>Week1-Part1</h1>
<p><a href="slides_pdfs/Week1-Part1.pdf" target="_blank">View PDF: Week1-Part1</a></p>
</section>
<section id="slides_pdfs-Week1-Part2" class="page-section ">
<h1>Week1-Part2</h1>
<p><a href="slides_pdfs/Week1-Part2.pdf" target="_blank">View PDF: Week1-Part2</a></p>
</section>
<section id="slides_pdfs-Week2" class="page-section ">
<h1>Week2</h1>
<p><a href="slides_pdfs/Week2.pdf" target="_blank">View PDF: Week2</a></p>
</section>
<section id="slides_pdfs-Week3" class="page-section ">
<h1>Week3</h1>
<p><a href="slides_pdfs/Week3.pdf" target="_blank">View PDF: Week3</a></p>
</section>
<section id="slides_pdfs-Week4" class="page-section ">
<h1>Week4</h1>
<p><a href="slides_pdfs/Week4.pdf" target="_blank">View PDF: Week4</a></p>
</section>
<section id="slides_pdfs-Week5" class="page-section ">
<h1>Week5</h1>
<p><a href="slides_pdfs/Week5.pdf" target="_blank">View PDF: Week5</a></p>
</section>
<section id="slides_pdfs-Week6" class="page-section ">
<h1>Week6</h1>
<p><a href="slides_pdfs/Week6.pdf" target="_blank">View PDF: Week6</a></p>
</section>
  </div>
  <script src="assets/script.js"></script>
</body>
</html>